{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Similarity Measures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Maye we need to transform the data: some categorical, scales, etc.\n",
    "Calculation of : Heterogeneous Distance Functions, General Coefficient of Similarity, and others that we find plausible.\n",
    "How to use categorical ( strings/names/description of something or event) data on similarity measures? And after this on models ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Todo/check and see:\n",
    "- Similarity measure : Euclidean distance, Manhattan distance, Minkowski distance, Cosine similarity, Jaccard similarity, Hamming distance, Levenshtein distance, Jaro-Winkler distance, Sorensen-Dice coefficient, and others. Also: Heterogeneous Distance Functions, General Coefficient of Similarity, and others that we find plausible.\n",
    "- Dissimilarity measure\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Common techniques: K-means, Hierarchical clustering, DBSCAN, Gaussian mixture models, and others. Also: Spectral clustering, Affinity propagation, Mean-shift, and others that we find plausible.\n",
    "- Partional\n",
    "    - Cluster compactness\n",
    "    - Cluster separation\n",
    "    - A clustering solution assigns all the objects to a cluster\n",
    "        • hard clustering: an object belongs to a single cluster\n",
    "        • fuzzy clustering: each object has a probability associated to belong to each cluster\n",
    "    - K-means\n",
    "     - pg28: best k \n",
    "        \n",
    "- Clustering Validation\n",
    "    - Supervised\n",
    "    - Unsupervised\n",
    "    • Cohesion coefficients - determine how compacts/cohesive are the\n",
    "    members of a group\n",
    "    • Separation coefficients - determine how different are the members of different groups\n",
    "    Silhouette Coefficient\n",
    "     - elbow method for the k\n",
    "     - PAM (Partitioning Around Medoids)\n",
    "     - CLARA (Clustering Large Applications)\n",
    "     - DBSCAN (Density-Based Spatial Clustering of Applications with Noise)\n",
    "     - OPTICS (Ordering Points To Identify the Clustering Structure)\n",
    "- Hierarchical : see pg 39 to 51\n",
    "    - Agglomerative Methods - bottom-up\n",
    "    - Divisive Methods - top-down\n",
    "    - Density-based\n",
    "\n",
    "Todo: at least 2 clustering methods, and 2 validation methods of every type (supervised and unsupervised) and Partional and Hierarchical. Choose the best ones and explain why.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get merged data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn import metrics, tree\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import StratifiedKFold, train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sqlalchemy import create_engine\n",
    "import seaborn as sns\n",
    "from sklearn import preprocessing\n",
    "\n",
    "\n",
    "merged_data = pd.read_csv('refined/final_data.csv',sep=';')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Partitional Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hierarchical Clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Aglomerative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: '1993-03-22'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [11], line 14\u001b[0m\n\u001b[1;32m     11\u001b[0m merged_data\u001b[39m.\u001b[39mhead()\n\u001b[1;32m     13\u001b[0m clustering_model \u001b[39m=\u001b[39m AgglomerativeClustering(n_clusters\u001b[39m=\u001b[39m\u001b[39m5\u001b[39m, affinity\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39meuclidean\u001b[39m\u001b[39m'\u001b[39m, linkage\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mward\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m---> 14\u001b[0m clustering_model\u001b[39m.\u001b[39;49mfit(merged_data)\n\u001b[1;32m     15\u001b[0m clustering_model\u001b[39m.\u001b[39mlabels_\n\u001b[1;32m     16\u001b[0m data_labels \u001b[39m=\u001b[39m clustering_model\u001b[39m.\u001b[39mlabels_\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/cluster/_agglomerative.py:914\u001b[0m, in \u001b[0;36mAgglomerativeClustering.fit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    896\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfit\u001b[39m(\u001b[39mself\u001b[39m, X, y\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[1;32m    897\u001b[0m     \u001b[39m\"\"\"Fit the hierarchical clustering from features, or distance matrix.\u001b[39;00m\n\u001b[1;32m    898\u001b[0m \n\u001b[1;32m    899\u001b[0m \u001b[39m    Parameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    912\u001b[0m \u001b[39m        Returns the fitted instance.\u001b[39;00m\n\u001b[1;32m    913\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 914\u001b[0m     X \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_validate_data(X, ensure_min_samples\u001b[39m=\u001b[39;49m\u001b[39m2\u001b[39;49m)\n\u001b[1;32m    915\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_fit(X)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/base.py:577\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[0;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[1;32m    575\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mValidation should be done on X, y or both.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    576\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mnot\u001b[39;00m no_val_X \u001b[39mand\u001b[39;00m no_val_y:\n\u001b[0;32m--> 577\u001b[0m     X \u001b[39m=\u001b[39m check_array(X, input_name\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mX\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mcheck_params)\n\u001b[1;32m    578\u001b[0m     out \u001b[39m=\u001b[39m X\n\u001b[1;32m    579\u001b[0m \u001b[39melif\u001b[39;00m no_val_X \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m no_val_y:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/utils/validation.py:856\u001b[0m, in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[1;32m    854\u001b[0m         array \u001b[39m=\u001b[39m array\u001b[39m.\u001b[39mastype(dtype, casting\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39munsafe\u001b[39m\u001b[39m\"\u001b[39m, copy\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[1;32m    855\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 856\u001b[0m         array \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39;49masarray(array, order\u001b[39m=\u001b[39;49morder, dtype\u001b[39m=\u001b[39;49mdtype)\n\u001b[1;32m    857\u001b[0m \u001b[39mexcept\u001b[39;00m ComplexWarning \u001b[39mas\u001b[39;00m complex_warning:\n\u001b[1;32m    858\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    859\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mComplex data not supported\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m{}\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(array)\n\u001b[1;32m    860\u001b[0m     ) \u001b[39mfrom\u001b[39;00m \u001b[39mcomplex_warning\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/core/generic.py:2070\u001b[0m, in \u001b[0;36mNDFrame.__array__\u001b[0;34m(self, dtype)\u001b[0m\n\u001b[1;32m   2069\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__array__\u001b[39m(\u001b[39mself\u001b[39m, dtype: npt\u001b[39m.\u001b[39mDTypeLike \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m np\u001b[39m.\u001b[39mndarray:\n\u001b[0;32m-> 2070\u001b[0m     \u001b[39mreturn\u001b[39;00m np\u001b[39m.\u001b[39;49masarray(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_values, dtype\u001b[39m=\u001b[39;49mdtype)\n",
      "\u001b[0;31mValueError\u001b[0m: could not convert string to float: '1993-03-22'"
     ]
    }
   ],
   "source": [
    "from sklearn.cluster import AgglomerativeClustering\n",
    "\n",
    "label_encoder = preprocessing.LabelEncoder()\n",
    "merged_data['trans_operation']= label_encoder.fit_transform(merged_data['trans_operation'])\n",
    "\n",
    "merged_data['trans_type'] = label_encoder.fit_transform(merged_data['trans_type'] )\n",
    "merged_data['account_date'] = label_encoder.fit_transform(merged_data['account_date'] )\n",
    "merged_data['loan_date'] = label_encoder.fit_transform(merged_data['loan_date'] )\n",
    "merged_data['client_birth_number'] = label_encoder.fit_transform(merged_data['client_birth_number'] )\n",
    "\n",
    "merged_data.head()\n",
    "\n",
    "clustering_model = AgglomerativeClustering(n_clusters=5, affinity='euclidean', linkage='ward')\n",
    "clustering_model.fit(merged_data)\n",
    "clustering_model.labels_\n",
    "data_labels = clustering_model.labels_\n",
    "sns.scatterplot(x='Annual Income (k$)', \n",
    "                y='Spending Score (1-100)', \n",
    "                data=merged_data,\n",
    "                hue=data_labels,\n",
    "                pallete=\"rainbow\").set_title('Labeled Customer Data')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Todo:\n",
    "- merged_data needs to be transformed to have 3 columns: year, month, day and drop date = year-month-day\n",
    "- user here the featuretools merged data result of the individual data understunding and preparation on every dataset\n",
    "that then we merge using the featuretools with entity set and relationship"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
