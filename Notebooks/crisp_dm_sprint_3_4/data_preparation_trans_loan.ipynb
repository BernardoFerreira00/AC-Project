{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data preparation: Transactions and loans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "from sklearn import preprocessing\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "pd.set_option('display.max_columns',None)\n",
    "%matplotlib inline\n",
    "\n",
    "trans_df = pd.read_csv(\"data/trans_dev.csv\",sep=\";\", low_memory=False)\n",
    "loan_df = pd.read_csv('data/loan_dev.csv', sep=';')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transaction preparation\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data quality issues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nothing to report os improvements to be made."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nothing to report os improvements to do know, but we will check the outliers in the next sprints with more detail and attention."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Inconsistent or incorrect data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No duplicates were found in the data understanding phase. Nothing to report."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Inconsistent or Incorrect Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Todo: \n",
    "\n",
    "Maybe we can try to search or try to reach some professional about technique/specific information about banks and accounts, but we will not do it now.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   trans_id  account_id  trans_date trans_type               trans_operation  \\\n",
      "0   1548749        5270      930113     credit                credit in cash   \n",
      "1   1548750        5270      930114     credit  collection from another bank   \n",
      "2   3393738       11265      930114     credit                credit in cash   \n",
      "3   3122924       10364      930117     credit                credit in cash   \n",
      "4   1121963        3834      930119     credit                credit in cash   \n",
      "\n",
      "   trans_amount  trans_balance  \n",
      "0         800.0          800.0  \n",
      "1       44749.0        45549.0  \n",
      "2        1000.0         1000.0  \n",
      "3        1100.0         1100.0  \n",
      "4         700.0          700.0  \n"
     ]
    }
   ],
   "source": [
    "#### Data cleaning, transformation and data quality changes\n",
    "trans_df.rename(columns={'date' : 'trans_date'}, inplace=True)\n",
    "trans_df.rename(columns={'type' : 'trans_type'}, inplace=True)\n",
    "trans_df.rename(columns={'operation' : 'trans_operation'}, inplace=True)\n",
    "trans_df.rename(columns={'amount' : 'trans_amount'}, inplace=True)\n",
    "trans_df.rename(columns={'balance' : 'trans_balance'}, inplace=True)\n",
    "trans_df.rename(columns={'k_symbol' : 'trans_k_symbol'}, inplace=True)\n",
    "trans_df.rename(columns={'bank' : 'trans_bank'}, inplace=True)\n",
    "trans_df.rename(columns={'account': 'trans_account'}, inplace=True)\n",
    "\n",
    "\n",
    "#as colunas bank e account não são necessárias, têm muitos valores nulos\n",
    "trans_df.drop(['trans_bank', 'trans_account','trans_k_symbol' ], axis=1, inplace=True)\n",
    "print(trans_df.head())\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Todo: \n",
    "- Handling Missing Values\n",
    "- Handling Duplicates\n",
    "- Handling Inconsistent or Incorrect Data\n",
    "    - statistical-based methods to detect outliers\n",
    "    - Domain knowledge\n",
    "    - • Inconsistency detection\n",
    "\n",
    "We change the names of many columns to make them more understandable and easier to work with. \n",
    "\n",
    "We decide to drop the columns account bank and k_symbol( now renamed to trans_account, trans_bank and trans_k_symbol) , due to the high number of missing values and more importantly, because nothing is being discovered that points they are relevant to the analysis. \n",
    "\n",
    "Todo: check if the missing values are relevant to the analysis.\n",
    "\n",
    "However, for the trans_k_symbol attribute we will now drop the column, but as mentioned in the data_understanding phase later on we will treat it more carefully and make sure if we can, for example, replace with the values in some way that would not introduce bias.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Todo: do it in the final\n",
    "Todo: detect here outliers and on feature engineering deal with them"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data transformation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### One-Hot Enconding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>trans_id</th>\n",
       "      <th>account_id</th>\n",
       "      <th>trans_date</th>\n",
       "      <th>trans_type</th>\n",
       "      <th>trans_operation</th>\n",
       "      <th>trans_amount</th>\n",
       "      <th>trans_balance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1548749</td>\n",
       "      <td>5270</td>\n",
       "      <td>930113</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>800.0</td>\n",
       "      <td>800.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1548750</td>\n",
       "      <td>5270</td>\n",
       "      <td>930114</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>44749.0</td>\n",
       "      <td>45549.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3393738</td>\n",
       "      <td>11265</td>\n",
       "      <td>930114</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>1000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3122924</td>\n",
       "      <td>10364</td>\n",
       "      <td>930117</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1100.0</td>\n",
       "      <td>1100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1121963</td>\n",
       "      <td>3834</td>\n",
       "      <td>930119</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>700.0</td>\n",
       "      <td>700.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   trans_id  account_id  trans_date  trans_type  trans_operation  \\\n",
       "0   1548749        5270      930113           0                2   \n",
       "1   1548750        5270      930114           0                0   \n",
       "2   3393738       11265      930114           0                2   \n",
       "3   3122924       10364      930117           0                2   \n",
       "4   1121963        3834      930119           0                2   \n",
       "\n",
       "   trans_amount  trans_balance  \n",
       "0         800.0          800.0  \n",
       "1       44749.0        45549.0  \n",
       "2        1000.0         1000.0  \n",
       "3        1100.0         1100.0  \n",
       "4         700.0          700.0  "
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import preprocessing\n",
    "label_encoder = preprocessing.LabelEncoder()\n",
    "trans_df['trans_operation']= label_encoder.fit_transform(trans_df['trans_operation'])\n",
    "\n",
    "trans_df['trans_type'] = label_encoder.fit_transform(trans_df['trans_type'] )\n",
    "trans_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Normalization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some common strategies:\n",
    "- Normalization: z-score\n",
    "- Binarization / One-Hot Enconding\n",
    "- Discretization\n",
    "- See more\n",
    "\n",
    "For machine learning layers:\n",
    "- BATCH NORMALIZATION\n",
    "- LOCAL RESPONSE NORMALIZATION\n",
    "- See more\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Min-Max Scaling (Range-based Normalization) \n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "#Transform date into datetime , get month, day, year columns we can do feature engineering later\n",
    "trans_df['trans_date'] = pd.to_datetime(trans_df['trans_date'], format='%y%m%d')\n",
    "# trans_date_year = []\n",
    "# trans_date_month = []\n",
    "# trans_date_day = []\n",
    "\n",
    "# for i in trans_df.index:\n",
    "#     trans_date_year.append(trans_df['trans_date'][i].year)\n",
    "#     trans_date_month.append(trans_df[\"trans_date\"][i].month)\n",
    "#     trans_date_day.append(trans_df['trans_date'][i].day )\n",
    "\n",
    "# trans_df['trans_year'] = trans_date_year\n",
    "# trans_df['trans_month'] = trans_date_month\n",
    "# trans_df['trans_day'] = trans_date_day\n",
    "#del trans_df['trans_date']\n",
    "\n",
    "#creating normalize objects\n",
    "save_trans_date = trans_df[\"trans_date\"].copy()\n",
    "save_trans_date\n",
    "del trans_df[\"trans_date\"]\n",
    "normMinMaxScaler = MinMaxScaler()\n",
    "normRobustScaler = RobustScaler()\n",
    "\n",
    "#Applying the normalization techniques\n",
    "trans_df_rs =  pd.DataFrame(normRobustScaler.fit_transform( trans_df),columns= trans_df.columns,)\n",
    "trans_df_mms = pd.DataFrame(normMinMaxScaler.fit_transform(trans_df), columns=trans_df.columns)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MinMaxScaler normalization: \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>trans_id</th>\n",
       "      <th>account_id</th>\n",
       "      <th>trans_type</th>\n",
       "      <th>trans_operation</th>\n",
       "      <th>trans_amount</th>\n",
       "      <th>trans_balance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>396685.000000</td>\n",
       "      <td>396685.000000</td>\n",
       "      <td>396685.000000</td>\n",
       "      <td>396685.000000</td>\n",
       "      <td>396685.000000</td>\n",
       "      <td>396685.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.336508</td>\n",
       "      <td>0.220318</td>\n",
       "      <td>0.305458</td>\n",
       "      <td>0.682007</td>\n",
       "      <td>0.065712</td>\n",
       "      <td>0.238043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.329435</td>\n",
       "      <td>0.177570</td>\n",
       "      <td>0.256677</td>\n",
       "      <td>0.263240</td>\n",
       "      <td>0.106370</td>\n",
       "      <td>0.094903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.106391</td>\n",
       "      <td>0.095862</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.001476</td>\n",
       "      <td>0.173558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.214030</td>\n",
       "      <td>0.194974</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.022593</td>\n",
       "      <td>0.214692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.345838</td>\n",
       "      <td>0.294877</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.075231</td>\n",
       "      <td>0.280723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            trans_id     account_id     trans_type  trans_operation  \\\n",
       "count  396685.000000  396685.000000  396685.000000    396685.000000   \n",
       "mean        0.336508       0.220318       0.305458         0.682007   \n",
       "std         0.329435       0.177570       0.256677         0.263240   \n",
       "min         0.000000       0.000000       0.000000         0.000000   \n",
       "25%         0.106391       0.095862       0.000000         0.600000   \n",
       "50%         0.214030       0.194974       0.500000         0.800000   \n",
       "75%         0.345838       0.294877       0.500000         0.800000   \n",
       "max         1.000000       1.000000       1.000000         1.000000   \n",
       "\n",
       "        trans_amount  trans_balance  \n",
       "count  396685.000000  396685.000000  \n",
       "mean        0.065712       0.238043  \n",
       "std         0.106370       0.094903  \n",
       "min         0.000000       0.000000  \n",
       "25%         0.001476       0.173558  \n",
       "50%         0.022593       0.214692  \n",
       "75%         0.075231       0.280723  \n",
       "max         1.000000       1.000000  "
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "print(\"MinMaxScaler normalization: \\n\")\n",
    "trans_df_mms.head()\n",
    "trans_df_mms.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RobustScaler normalization: \n",
      "\n",
      "   trans_id  account_id  trans_type  trans_operation  trans_amount  \\\n",
      "0  0.862365    1.346578        -1.0             -2.0     -0.180777   \n",
      "1  0.862366    1.346578        -1.0             -4.0      6.715889   \n",
      "2  2.954504    3.993377        -1.0             -2.0     -0.149392   \n",
      "3  2.647413    3.595585        -1.0             -2.0     -0.133699   \n",
      "4  0.378407    0.712583        -1.0             -2.0     -0.196469   \n",
      "\n",
      "   trans_balance  \n",
      "0      -1.356298  \n",
      "1       0.656096  \n",
      "2      -1.347304  \n",
      "3      -1.342807  \n",
      "4      -1.360795  \n",
      "            trans_id     account_id     trans_type  trans_operation  \\\n",
      "count  396685.000000  396685.000000  396685.000000    396685.000000   \n",
      "mean        0.511506       0.127344      -0.389085        -0.589964   \n",
      "std         1.375817       0.892242       0.513354         1.316198   \n",
      "min        -0.893850      -0.979691      -1.000000        -4.000000   \n",
      "25%        -0.449529      -0.498013      -1.000000        -1.000000   \n",
      "50%         0.000000       0.000000       0.000000         0.000000   \n",
      "75%         0.550471       0.501987       0.000000         0.000000   \n",
      "max         3.282441       4.045033       1.000000         1.000000   \n",
      "\n",
      "        trans_amount  trans_balance  \n",
      "count  396685.000000  396685.000000  \n",
      "mean        0.584630       0.217892  \n",
      "std         1.442191       0.885570  \n",
      "min        -0.306316      -2.003368  \n",
      "25%        -0.286308      -0.383838  \n",
      "50%         0.000000       0.000000  \n",
      "75%         0.713692       0.616162  \n",
      "max        13.251942       7.327989  \n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"RobustScaler normalization: \\n\")\n",
    "print(trans_df_rs.head())\n",
    "print(trans_df_rs.describe())\n",
    "print(\"\\n\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Data transformation: final report** \n",
    "\n",
    "\n",
    "What we have done:\n",
    "- One-hot encoding on categorical nominal attribute trans_operation and trans_type ( maybe also on trans_k_symbol if we decido to keep it )\n",
    "- Change values withdrawal in cash to withdrawal on trans_type attribute\n",
    "- change the values on trans_ammount attribute to be negative when trans_type attribute values are withdrawal\n",
    "- change trans_date attribute to datetime type :year-month-day\n",
    "- add trans_year attribute to the dataset getting information from trans_date\n",
    "- add trans_month attribute to the dataset getting information from trans_date\n",
    "- drop trans_date collumn \n",
    "- Min-Max Scaling (Range-based Normalization) not so sensitive to outliers\n",
    "- Also change float values ?!?!?\n",
    "\n",
    "Todo:\n",
    "- In the future, apply : LOCAL RESPONSE NORMALIZATION and or BATCH NORMALIZATION ( ML layer )!!!\n",
    "- On every dataset and the merged/final dataset check distributions and change/adapte to other types of normalization if needed\n",
    "- check for normal distribution data and apply z-score normalization if needed\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some common strategies:\n",
    "- Log Transform\n",
    "- Imputation\n",
    "- Dealing With Dates\n",
    "- Outliers: treat the outliers discovered in the data_preparation phase (data cleaning) and data understanding phase\n",
    "    - DBSCAN and Isolation Forest, percentiles, z-score using data visualization on data understanding phase\n",
    "- Binning\n",
    "- one hot encoding ( done on data transformation phase )\n",
    "- scaling : Standardization or Normalization ( done on data transformation phase using Min-MaxScaler)\n",
    "- Automated Feature Engineering: Featuretools\n",
    "\n",
    "TODO and see:\n",
    "- relative values instead of absolute values\n",
    "- Time Delay Embedding\n",
    "- create ratios and proportions\n",
    "- • express known case dependencies; use feature engineering to express the dependencies ( relationships between datasets)\n",
    "- see more common techniques on feature engineering \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Deep Feature Synthesis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data frame with robust scaler normalization\n",
    "# Automated feature engineering using featuretools\n",
    "#Feature Synthesis\n",
    "import featuretools as ft\n",
    "from featuretools.primitives import Sum\n",
    "from woodwork.logical_types import Categorical\n",
    "from woodwork.logical_types import Datetime\n",
    "import woodwork as ww\n",
    "import data_understanding_utils as du\n",
    "# Create an entityset and add the entity\n",
    "# even trans_operation and trans_type are numerical, we categorize them as categorical to use DF_rsS\n",
    "# append again the trans_date column\n",
    "trans_df[\"trans_date\"] = save_trans_date\n",
    "trans_df_mms[\"trans_date\"] = save_trans_date\n",
    "trans_df_rs[\"trans_date\"] = save_trans_date\n",
    "\n",
    "trans_df.ww.init(name=\"ww_t_df\")\n",
    "trans_df_mms.ww.init(name=\"ww_t_df_mms\")\n",
    "trans_df_rs.ww.init(name=\"ww_t_df_rs\")\n",
    "trans_df.ww.set_types(logical_types= {\"trans_operation\": Categorical, \n",
    "                        \"trans_type\": Categorical, \"trans_date\": Datetime})\n",
    "trans_df.ww.types\n",
    "\n",
    "trans_df_mms.ww.set_types(logical_types= {\"trans_operation\": Categorical, \n",
    "                        \"trans_type\": Categorical, \"trans_date\": Datetime})\n",
    "trans_df_mms.ww.types\n",
    "\n",
    "trans_df_rs.ww.set_types(logical_types= {\"trans_operation\": Categorical, \n",
    "                        \"trans_type\": Categorical, \"trans_date\": Datetime})\n",
    "trans_df_rs.ww.types\n",
    "\n",
    "trans_df.ww.set_index(\"trans_id\")\n",
    "trans_df.ww.set_time_index(\"trans_date\")\n",
    "trans_df_mms.ww.set_index(\"trans_id\")\n",
    "trans_df_mms.ww.set_time_index(\"trans_date\")\n",
    "trans_df_rs.ww.set_index(\"trans_id\")\n",
    "trans_df_rs.ww.set_time_index(\"trans_date\")\n",
    "#mean year, month balance for each account\n",
    "save_balance_month_year_df = trans_df.groupby(by=[\"account_id\",trans_df[\"trans_date\"].dt.year,trans_df[\"trans_date\"].dt.month])['trans_balance'].mean()\n",
    "save_balance_month_year_df_mms = trans_df_mms.groupby(by=[\"account_id\",trans_df_mms[\"trans_date\"].dt.year,trans_df_mms[\"trans_date\"].dt.month])['trans_balance'].mean()\n",
    "save_balance_month_year_df_rs = trans_df_rs.groupby(by=[\"account_id\",trans_df_rs[\"trans_date\"].dt.year,trans_df_rs[\"trans_date\"].dt.month])['trans_balance'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wolfcuanhamarws/.local/lib/python3.10/site-packages/featuretools/entityset/entityset.py:754: UserWarning: A Woodwork-initialized DataFrame was provided, so the following parameters were ignored: index, time_index, dataframe_name\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Built 9 features\n",
      "Elapsed: 00:05 | Progress: 100%|██████████\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>account_id</th>\n",
       "      <th>trans_type</th>\n",
       "      <th>trans_operation</th>\n",
       "      <th>trans_amount</th>\n",
       "      <th>trans_balance</th>\n",
       "      <th>DAY(trans_date)</th>\n",
       "      <th>MONTH(trans_date)</th>\n",
       "      <th>WEEKDAY(trans_date)</th>\n",
       "      <th>YEAR(trans_date)</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>trans_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>24</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3679.0</td>\n",
       "      <td>4679.0</td>\n",
       "      <td>13</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>1995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>12600.0</td>\n",
       "      <td>17279.0</td>\n",
       "      <td>23</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>1995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3530438</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>19.2</td>\n",
       "      <td>17298.2</td>\n",
       "      <td>30</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>1995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3679.0</td>\n",
       "      <td>20977.2</td>\n",
       "      <td>13</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>1995</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          account_id trans_type trans_operation  trans_amount  trans_balance  \\\n",
       "trans_id                                                                       \n",
       "1                  1          0               2        1000.0         1000.0   \n",
       "5                  1          0               0        3679.0         4679.0   \n",
       "199                1          0               2       12600.0        17279.0   \n",
       "3530438            1          0               5          19.2        17298.2   \n",
       "6                  1          0               0        3679.0        20977.2   \n",
       "\n",
       "         DAY(trans_date) MONTH(trans_date) WEEKDAY(trans_date)  \\\n",
       "trans_id                                                         \n",
       "1                     24                 3                   4   \n",
       "5                     13                 4                   3   \n",
       "199                   23                 4                   6   \n",
       "3530438               30                 4                   6   \n",
       "6                     13                 5                   5   \n",
       "\n",
       "         YEAR(trans_date)  \n",
       "trans_id                   \n",
       "1                    1995  \n",
       "5                    1995  \n",
       "199                  1995  \n",
       "3530438              1995  \n",
       "6                    1995  "
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#print(trans_df.head())\n",
    "# trans_df.drop('trans_id', axis=1, inplace=True)\n",
    "# print(trans_df.head())\n",
    "# print(trans_df.isnull().sum())\n",
    "# du.check_duplicates(trans_df,\"transaction\",trans_df.columns)\n",
    "entitySet_t_df = ft.EntitySet(id =\"trans_df\")\n",
    "entitySet_t_df\n",
    "entitySet_t_df = entitySet_t_df.add_dataframe( dataframe= trans_df ,dataframe_name= \"trans_df\" , index= \"trans_id\",\n",
    "                        time_index = 'trans_date')\n",
    "\n",
    "# # Here we will only use on transaction dataframe\n",
    "# #Create cutoff time to use DFS\n",
    "\n",
    "# #Check also max_depth , verbose and n_jobs\n",
    "ft_trans_df_matrix , features_trans__df_defs = ft.dfs( entityset = entitySet_t_df,  target_dataframe_name= trans_df.ww.name,\n",
    "                                                     \n",
    "                                      max_depth = 1, verbose = 1, n_jobs = 1)\n",
    "    \n",
    "ft_trans_df_matrix.sort_values(by=[\"account_id\",\"YEAR(trans_date)\",\"MONTH(trans_date)\",\"DAY(trans_date)\"] ,inplace=True, ascending=True)\n",
    "\n",
    "ft_trans_df_matrix.head(5)\n",
    "\n",
    "# #same for trans_df_mms and trans_df_rs\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Built 9 features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wolfcuanhamarws/.local/lib/python3.10/site-packages/featuretools/entityset/entityset.py:754: UserWarning: A Woodwork-initialized DataFrame was provided, so the following parameters were ignored: index, time_index, dataframe_name\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed: 00:05 | Progress: 100%|██████████\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>account_id</th>\n",
       "      <th>trans_type</th>\n",
       "      <th>trans_operation</th>\n",
       "      <th>trans_amount</th>\n",
       "      <th>trans_balance</th>\n",
       "      <th>DAY(trans_date)</th>\n",
       "      <th>MONTH(trans_date)</th>\n",
       "      <th>WEEKDAY(trans_date)</th>\n",
       "      <th>YEAR(trans_date)</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>trans_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0.000000</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.011574</td>\n",
       "      <td>0.070307</td>\n",
       "      <td>24</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.000001</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.042581</td>\n",
       "      <td>0.088038</td>\n",
       "      <td>13</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>1995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.000054</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.145833</td>\n",
       "      <td>0.148761</td>\n",
       "      <td>23</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>1995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.958594</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000222</td>\n",
       "      <td>0.148854</td>\n",
       "      <td>30</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>1995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.000001</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.042581</td>\n",
       "      <td>0.166584</td>\n",
       "      <td>13</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>1995</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          account_id trans_type trans_operation  trans_amount  trans_balance  \\\n",
       "trans_id                                                                       \n",
       "0.000000         0.0        0.0             0.4      0.011574       0.070307   \n",
       "0.000001         0.0        0.0             0.0      0.042581       0.088038   \n",
       "0.000054         0.0        0.0             0.4      0.145833       0.148761   \n",
       "0.958594         0.0        0.0             1.0      0.000222       0.148854   \n",
       "0.000001         0.0        0.0             0.0      0.042581       0.166584   \n",
       "\n",
       "         DAY(trans_date) MONTH(trans_date) WEEKDAY(trans_date)  \\\n",
       "trans_id                                                         \n",
       "0.000000              24                 3                   4   \n",
       "0.000001              13                 4                   3   \n",
       "0.000054              23                 4                   6   \n",
       "0.958594              30                 4                   6   \n",
       "0.000001              13                 5                   5   \n",
       "\n",
       "         YEAR(trans_date)  \n",
       "trans_id                   \n",
       "0.000000             1995  \n",
       "0.000001             1995  \n",
       "0.000054             1995  \n",
       "0.958594             1995  \n",
       "0.000001             1995  "
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# trans_df_mms\n",
    "\n",
    "entitySet_t_df_mms = ft.EntitySet(id =\"trans_df_mms\")\n",
    "entitySet_t_df_mms\n",
    "entitySet_t_df_mms = entitySet_t_df_mms.add_dataframe( dataframe= trans_df_mms ,dataframe_name= \"trans_df_mms\" , index= \"trans_id\",\n",
    "                        time_index = 'trans_date')\n",
    "\n",
    "# # Here we will only use on transaction dataframe\n",
    "# #Create cutoff time to use DFS\n",
    "\n",
    "# #Check also max_depth , verbose and n_jobs\n",
    "ft_trans_df_mms_matrix , features_trans_df_mms_defs = ft.dfs( entityset = entitySet_t_df_mms, target_dataframe_name= trans_df_mms.ww.name,\n",
    "                                                     \n",
    "                                           max_depth = 1, verbose = 1, n_jobs = 1)\n",
    "    \n",
    "ft_trans_df_mms_matrix.sort_values(by=[\"account_id\",\"YEAR(trans_date)\",\"MONTH(trans_date)\",\"DAY(trans_date)\"] ,inplace=True, ascending=True)\n",
    "\n",
    "ft_trans_df_mms_matrix.head(5)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wolfcuanhamarws/.local/lib/python3.10/site-packages/featuretools/entityset/entityset.py:754: UserWarning: A Woodwork-initialized DataFrame was provided, so the following parameters were ignored: index, time_index, dataframe_name\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Built 9 features\n",
      "Elapsed: 00:05 | Progress: 100%|██████████\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>account_id</th>\n",
       "      <th>trans_type</th>\n",
       "      <th>trans_operation</th>\n",
       "      <th>trans_amount</th>\n",
       "      <th>trans_balance</th>\n",
       "      <th>DAY(trans_date)</th>\n",
       "      <th>MONTH(trans_date)</th>\n",
       "      <th>WEEKDAY(trans_date)</th>\n",
       "      <th>YEAR(trans_date)</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>trans_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>-0.893850</th>\n",
       "      <td>-0.979691</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>-0.149392</td>\n",
       "      <td>-1.347304</td>\n",
       "      <td>24</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>-0.893846</th>\n",
       "      <td>-0.979691</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-4.0</td>\n",
       "      <td>0.271008</td>\n",
       "      <td>-1.181857</td>\n",
       "      <td>13</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>1995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>-0.893626</th>\n",
       "      <td>-0.979691</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>1.670930</td>\n",
       "      <td>-0.615226</td>\n",
       "      <td>23</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>1995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3.109517</th>\n",
       "      <td>-0.979691</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.303303</td>\n",
       "      <td>-0.614363</td>\n",
       "      <td>30</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>1995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>-0.893845</th>\n",
       "      <td>-0.979691</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-4.0</td>\n",
       "      <td>0.271008</td>\n",
       "      <td>-0.448916</td>\n",
       "      <td>13</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>1995</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           account_id trans_type trans_operation  trans_amount  trans_balance  \\\n",
       "trans_id                                                                        \n",
       "-0.893850   -0.979691       -1.0            -2.0     -0.149392      -1.347304   \n",
       "-0.893846   -0.979691       -1.0            -4.0      0.271008      -1.181857   \n",
       "-0.893626   -0.979691       -1.0            -2.0      1.670930      -0.615226   \n",
       " 3.109517   -0.979691       -1.0             1.0     -0.303303      -0.614363   \n",
       "-0.893845   -0.979691       -1.0            -4.0      0.271008      -0.448916   \n",
       "\n",
       "          DAY(trans_date) MONTH(trans_date) WEEKDAY(trans_date)  \\\n",
       "trans_id                                                          \n",
       "-0.893850              24                 3                   4   \n",
       "-0.893846              13                 4                   3   \n",
       "-0.893626              23                 4                   6   \n",
       " 3.109517              30                 4                   6   \n",
       "-0.893845              13                 5                   5   \n",
       "\n",
       "          YEAR(trans_date)  \n",
       "trans_id                    \n",
       "-0.893850             1995  \n",
       "-0.893846             1995  \n",
       "-0.893626             1995  \n",
       " 3.109517             1995  \n",
       "-0.893845             1995  "
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# trans_df_rs\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "entitySet_t_df_rs = ft.EntitySet(id =\"trans_df_rs\")\n",
    "entitySet_t_df_rs\n",
    "entitySet_t_df_rs = entitySet_t_df_rs.add_dataframe( dataframe= trans_df_rs ,dataframe_name= \"trans_df_rs\" , index= \"trans_id\",\n",
    "                        time_index = 'trans_date')\n",
    "\n",
    "# # Here we will only use on transaction dataframe\n",
    "# #Create cutoff time to use DFS\n",
    "\n",
    "# #Check also max_depth , verbose and n_jobs\n",
    "ft_trans_df_rs_matrix , features_trans_df_rs_defs = ft.dfs( entityset = entitySet_t_df_rs, target_dataframe_name= trans_df_rs.ww.name , max_depth = 1, verbose = 1, n_jobs = 1)\n",
    "    \n",
    "ft_trans_df_rs_matrix.sort_values(by=[\"account_id\",\"YEAR(trans_date)\",\"MONTH(trans_date)\",\"DAY(trans_date)\"] ,inplace=True, ascending=True)\n",
    "\n",
    "ft_trans_df_rs_matrix.head(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Entityset: trans_df\n",
       "  DataFrames:\n",
       "    ww_t_df [Rows: 396685, Columns: 7]\n",
       "  Relationships:\n",
       "    No relationships"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "entitySet_t_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Entityset: trans_df_mms\n",
       "  DataFrames:\n",
       "    ww_t_df_mms [Rows: 396685, Columns: 7]\n",
       "  Relationships:\n",
       "    No relationships"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "entitySet_t_df_mms\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Entityset: trans_df_rs\n",
       "  DataFrames:\n",
       "    ww_t_df_rs [Rows: 396685, Columns: 7]\n",
       "  Relationships:\n",
       "    No relationships"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "entitySet_t_df_rs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "#join all the transaction dataframes with the year_month_balance dataframe\n",
    "# ft_trans_df_matrix.join(save_balance_month_year_df, on=\"account_id\", how= \"inner\")\n",
    "# ft_trans_df_mms_matrix.join(save_balance_month_year_df, on=\"account_id\", how= \"inner\")\n",
    "# ft_trans_df_mms_matrix.join(save_balance_month_year_df, on=\"account_id\", how= \"inner\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Tuning Deep Feature Synthesis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Final report:**\n",
    "\n",
    "Done:\n",
    "- Dealing with dates : Transform date into datetime , get month, day, year columns we can do feature engineering later. This was done on data transformation phase so we can normalize in a way  that in the end we can run all cells at once .\n",
    "- Scaling was done: MinMaxScaler() and  RobustScaler().\n",
    "- Use Deep Feature Synthesis to create new features from the existing ones. We will do it here and on the final dataset, after merging all relevant atributes of all data datasets.\n",
    "\n",
    "TODO: \n",
    "- Categorical imputation : can be usefull for the trans_k_symbol column !! if we decide to keep it\n",
    "- Scaling: StandardScaler() and Normalization: z-score if we find to have normal distribution in the data\n",
    "- merge the mean, year, month balance with the final ft_matrix and mergo with loans dataset to get more feature engineering\n",
    "- merge\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data and Dimensionality Reduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Some Strategies**\n",
    "• Feature Selection\n",
    "• Principal Components Analysis (PCA)\n",
    "• Singular Value Decomposition (SVD)\n",
    "\n",
    "TODO:\n",
    "- See others"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sampling Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' from ._adasyn import ADASYN\n",
    "from ._random_over_sampler import RandomOverSampler\n",
    "from ._smote import SMOTE\n",
    "from ._smote import BorderlineSMOTE\n",
    "from ._smote import KMeansSMOTE\n",
    "from ._smote import SVMSMOTE\n",
    "from ._smote import SMOTENC\n",
    "from ._smote import SMOTEN\n",
    "'''\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.over_sampling import KMeansSMOTE\n",
    "def split_data(X, y, test_size):\n",
    "    return train_test_split(X, y, test_size=0.3, random_state=42, shuffle=False)\n",
    "\n",
    "def smote_sampling(X_train, y_train):\n",
    "    sm = SMOTE(random_state=42)\n",
    "    return sm.fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature Extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Export new transaction data to csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "ft_trans_df_matrix.to_csv('refined/transaction_df.csv')\n",
    "ft_trans_df_mms_matrix.to_csv('refined/transaction_df_mms.csv')\n",
    "ft_trans_df_mms_matrix.to_csv('refined/transaction_df_rs.csv')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loan preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Todo:\n",
    "    transactions:as transactions vão passar apenas a ter: média do balanço das transações por mês de cada ano,balanço mensal ,soma do nº de transações mensal e anual?, taxa de esforço mensal. Isso assim reduz imenso a dimensão da merge data e não perde muita informação .\n",
    "    - loans: for every account: number of clients, loan_ammount, loan_duration,loan_payments(year), loan_paymentos_month = loan_payments/12, loan_duration -> cruzar com a transactions, client e district e account_frequency ( check better this)\n",
    "    - client; mix with the other datasets and: get age of client when loan_age =x and loan_status 1 or 0, gender\n",
    "    - district: check better this\n",
    "    - client is the most importante object to compare with every other feature \n",
    "        - client:gender,account number of loans, number of people on the same account, number of accounts ?, the other informations above, average salayr for his district, and other info in district, number of transactions, ....\n",
    "        Focus on: for every pair client,account -> info relationship with the other tables\n",
    "     - What to do about the missing values ?? , outliers and duplicates ?? and inconsistent or incorrect data ?? check\n",
    "\n",
    "     - WHat to do for clients with more than one account ?? and for more than one loan ?? (Example: one loand payed, other not)-> count number of loan payed ?check this !!!\n",
    "     - condensate information: on row for every client,account,loan -> number of loans, number of people on the same account, number of accounts ?, the other informations above, average salayr for his district, and other info in district, number of transactions, .... just stay with the owners and count the number of clients on the same account(it seems logic: the owner is who have always something to say if any loan is requested)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
